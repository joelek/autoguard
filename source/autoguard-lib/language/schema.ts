import * as shared from "../shared";
import * as tokenization from "../tokenization";
import * as types from "./types";

export class Schema {
	types: Map<string, types.Type>;

	private getImports(): Array<shared.Import> {
		let imports = new Map<string, string[]>();
		for (let [key, value] of this.types) {
			let entries = value.getImports();
			for (let entry of entries) {
				imports.set(entry.typename, entry.path);
			}
		}
		return Array.from(imports.entries())
			.sort((one, two) => one[0].localeCompare(two[0]))
			.map((entry) => {
				return {
					path: entry[1],
					typename: entry[0]
				};
			});
	}

	constructor() {
		this.types = new Map<string, types.Type>();
	}

	add(key: string, value: types.Type): this {
		this.types.set(key, value);
		return this;
	}

	generateModule(options: shared.Options): string {
		let lines = new Array<string>();
		lines.push("// This file was auto-generated by @joelek/ts-autoguard. Edit at own risk.");
		lines.push("");
		let imports = this.getImports();
		for (let entry of imports) {
			lines.push("import { " + entry.typename + " } from \"" + entry.path.join("/") + "\";");
		}
		lines.push("import * as autoguard from \"@joelek/ts-autoguard\";");
		lines.push("");
		for (let [key, value] of this.types) {
			lines.push("export type " + key + " = " + value.generateType(options) + ";");
			lines.push("");
			lines.push("export const " + key + " = " + value.generateTypeGuard({ ...options, eol: options.eol }) + ";");
			lines.push("");
		}
		let autoguard = new types.ObjectType();
		for (let [key, value] of this.types) {
			autoguard.add(key, {
				type: new types.ReferenceType([], key),
				optional: false
			});
		}
		lines.push("export namespace Autoguard {");
		lines.push("	" + "export type Guards = " + autoguard.generateType({ ...options, eol: options.eol + "\t" }) + ";");
		lines.push("");
		lines.push("	" + "export const Guards = " + autoguard.generateType({ ...options, eol: options.eol + "\t" }) + ";");
		lines.push("};");
		lines.push("");
		return lines.join(options.eol);
	}

	static parse(tokenizer: tokenization.Tokenizer): Schema {
		return tokenizer.newContext((read, peek) => {
			tokenization.expect(read(), "{");
			let instance = new Schema();
			if (peek()?.value !== "}") {
				while (true) {
					let identifier = tokenization.expect(read(), "IDENTIFIER").value;
					tokenization.expect(read(), ":");
					let type = types.Type.parse(tokenizer);
					instance.add(identifier, type);
					if (peek()?.value !== ",") {
						break;
					}
					tokenization.expect(read(), ",");
				}
			}
			tokenization.expect(read(), "}");
			if (peek() != null) {
				throw `Expected end of stream!`;
			}
			return instance;
		});
	}
};
